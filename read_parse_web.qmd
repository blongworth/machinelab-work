---
title: "Parse LECS Web"
format: html
editor: source
params:
  start_date: 2024-03-07
---

Get and parse data sent to LECS website. Data from `r params$start_date` to present.



# Get Data

```{r}
#| warning: false
#| message: false

library(tidyverse)
library(lubridate)
library(mlabtools)

theme_set(theme_bw())
options(digits.secs=3)

time_offset = as.POSIXct("2024-03-06 08:42:43") - as.POSIXct("2019-01-01 00:00:00")

# plotting function
plot_mean <- function(data, parameter, err) {
  data |> 
    ggplot(aes(x = timestamp_mean, 
               y = {{parameter}},
               ymin = {{parameter}} - {{err}},
               ymax = {{parameter}} + {{err}})) +
    geom_line(color = "gray") +
    geom_pointrange() +
    labs(x = NULL)
}
```

## Get and process data

Get data from website. 

Use `start_date` parameter to limit download.

```{r}
df_raw <- lecs_read_web(start_date = params$start_date)
```

Add row, type, send and line number

```{r}
df <- lecs_add_metadata(df_raw)
```

Separate data into post times, met, status, and adv data


```{r}
post_times <- lecs_post_times(df) |> 
  mutate(timestamp = if_else(timestamp < as.POSIXct("2020-01-01"),
                 timestamp + time_offset,
                 timestamp))
met <- lecs_met_data(df) |> 
  mutate(timestamp = if_else(timestamp < as.POSIXct("2020-01-01"),
                 timestamp + time_offset,
                 timestamp))
status <- lecs_status_data(df) |> 
  mutate(timestamp = if_else(timestamp < as.POSIXct("2020-01-01"),
                 timestamp + time_offset,
                 timestamp))
adv_data <- lecs_adv_data(df, rinko_cals) |> 
  mutate(missing = lecs_missing(count, line))
```

Quick ADV time alignment


```{r}
#| eval: false
find_nearest_row <- function(row_number) {
  return(which.min(abs(status$row_num - row_number)))
}

adv_data$timestamp_s <- status$timestamp[sapply(adv_data$row_num, find_nearest_row)]
```

Real ADV time alignment

time per line

```{r}
#| eval: true
adv_data <- make_lecs_ts(adv_data, status)
lps <- NA
```

ADV time alignment speed: `r lps` lines per second.

Filter bad data

```{r}
status_qc <- status |> 
  filter(soundspeed > 1450, 
         adv_day < 32, adv_month > 0, adv_month < 13, 
         adv_min < 61, adv_hour < 24, adv_year < 100,
         #timestamp > "2023-01-01",
         timestamp < "2024-10-01")

adv_data_qc <- adv_data |> 
  filter(count >= 0, count < 256, 
         #ana_in2 == 1, 
         #timestamp > "2023-01-01",
         timestamp < "2024-10-01")
```

Calculate per-send means

```{r}
met_mean <- met |> 
  group_by(send) |> 
  summarise(across(everything(), 
                   list(mean = ~ mean(.x, na.rm = TRUE), 
                        sd = ~ sd(.x, na.rm = TRUE))))

status_mean <- status_qc |> 
  select(send, timestamp, bat) |> 
  group_by(send) |> 
  summarise(across(c(timestamp, bat), 
                   list(mean = ~ mean(.x, na.rm = TRUE), 
                        sd = ~ sd(.x, na.rm = TRUE))))

adv_data_mean <- adv_data_qc |> 
  select(send, missing, timestamp, 
         pressure, temp, 
         u, v, w, corr1, corr2, corr3,
         DO_percent, pH) |> 
  group_by(send) |> 
  summarise(across(everything(), 
                   list(mean = ~ mean(.x, na.rm = TRUE), 
                        sd = ~ sd(.x, na.rm = TRUE))),
            missing_frac = sum(missing, na.rm = TRUE) / (sum(missing, na.rm = TRUE) + n()),
            N = n())
```

#### Last post was `r max(post_times$timestamp)`

### Met data

#### PAR

```{r}
met_mean |> 
  plot_mean(PAR_mean, PAR_sd)
```

#### Wind Speed

```{r}
met_mean |> 
  plot_mean(wind_speed_mean, wind_speed_sd) +
  labs(title = "Wind Speed",
       y = "Wind Speed (m/s)")
```

#### Wind direction

```{r}
ggplot(met_mean, aes(wind_dir_mean, wind_speed_mean)) +
  geom_point() +
  coord_polar() +
  scale_x_continuous(limits = c(0,360),
                     breaks = seq(0, 360, by = 45),
                     minor_breaks = seq(0, 360, by = 15))
```

### Status

#### Battery

```{r}
status_mean |> 
  plot_mean(bat_mean, bat_sd) +
  geom_smooth() +
  labs(title = "Battery Voltage",
       y = "Volts")
```

### ADV Data

#### pressure

```{r}
adv_data_mean |> 
  plot_mean(pressure_mean, pressure_sd) +
  scale_y_reverse() +
  labs(title = "Pressure",
       y = "Pressure (dbar)")
```

#### pH

Data issues cause wild flyers

```{r}
adv_data_qc |> 
  ggplot(aes(timestamp, pH)) +
  geom_point()
```


```{r}
adv_data_mean |> 
  plot_mean(pH_mean, pH_sd) +
  labs(title = "pH")
```

#### Temperature

```{r}
adv_data_mean |> 
  plot_mean(temp_mean, temp_sd) +
  labs(title = "Temperature",
       y = "Temp (C)")
```

#### Oxygen

```{r}
adv_data_mean |> 
  plot_mean(DO_percent_mean, DO_percent_sd) +
  labs(title = "Oxygen")
```

#### ADV Data proper

Correlation by send

```{r}
adv_data_mean |> 
  select(timestamp_mean, corr1_mean, corr2_mean, corr3_mean) |> 
  pivot_longer(starts_with("corr")) |>
  ggplot(aes(timestamp_mean, value, color = name)) +
  geom_smooth(aes(timestamp_mean, value), se = FALSE) +
  geom_smooth(aes(timestamp_mean, value, color = NULL)) +
  geom_point() +
  labs(title = "ADV correlation",
       x = NULL,
       y = "Correlation")
```

Vertical velocity

```{r}
adv_data_mean |> 
  plot_mean(w_mean, w_sd) +
  ylim(-0.1, 0.1) +
  labs(title = "Vertical velocity")
```

Alongshore velocity

Positive is southerly current

```{r}
adv_data_mean |> 
  plot_mean(u_mean, u_sd) +
  ylim(-0.5, 0.5) +
  labs(title = "Alongshore velocity")
```

Offshore velocity

Positive is away from shore

```{r}
adv_data_mean |> 
  plot_mean(v_mean, v_sd) +
  ylim(-0.5, 0.5) +
  labs(title = "Offshore velocity")
```


## Missing data

Missing data by row. Determined by looking at gaps in cycle number.

```{r}
adv_data |> 
  ggplot(aes(row_num, missing)) +
  geom_point() +
  labs(title = "Missing data by row",
       x = NULL,
       y = "Missing")
```

Fraction of data missing. Ratio of total missing rows (as above)
to expected rows (rows in send + sum of missing rows).

```{r}
adv_data_mean |> 
  ggplot(aes(timestamp_mean, missing_frac)) +
  geom_point() +
  labs(title = "Fraction missing by send",
       x = NULL,
       y = "Fraction missing")
```

Most missing data is in first 25 lines per send. This is the beginning of a new
file. This is likely a gap as DAQ gets started again after pausing for send.
The following plot is missing fraction without the first 25 lines of each send.

```{r}
adv_data_qc <- adv_data |> 
  filter(count >= 0, count < 256, 
         #ana_in2 == 1, 
         line > 30,
         #timestamp > "2023-01-01",
         timestamp < "2024-10-01")

adv_data_mean <- adv_data_qc |> 
  select(send, missing, timestamp, pressure, ph_counts, temp, DO_percent) |> 
  group_by(send) |> 
  summarise(across(everything(), 
                   list(mean = ~ mean(.x, na.rm = TRUE), 
                        sd = ~ sd(.x, na.rm = TRUE))),
            missing_frac = sum(missing, na.rm = TRUE) / (sum(missing, na.rm = TRUE) + n()),
            N = n())
```

```{r}
adv_data_mean |> 
  ggplot(aes(timestamp_mean, missing_frac)) +
  geom_point() +
  labs(title = "Fraction missing by send, without first 25 lines",
       x = NULL,
       y = "Fraction missing")
```

## Post times

```{r}
knitr::kable(post_times)
```

Lines per post

```{r}
post_times |> 
  ggplot(aes(timestamp, row_count)) +
  geom_point() +
  labs(title = "Lines per post",
       x = NULL,
       y = "Lines")
```
