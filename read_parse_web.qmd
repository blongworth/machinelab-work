---
title: "Parse LECS Web"
format: html
editor: source
params:
  start_date: 2024-01-01
---

Get and parse data sent to LECS website. Data from `r params$start_date` to present.



# Get Data

```{r}
#| warning: false
#| message: false

library(tidyverse)
library(rvest)
library(lubridate)
library(mlabtools)
library(shiny)
library(htmlwidgets)

theme_set(theme_bw())

# RINKO_CALS
A = -1.219367e1
B = 2.134089e1
C = -3.559172e00
D = 6.691104e-01

# plotting function
plot_mean <- function(data, parameter, err) {
  data |> 
    ggplot(aes(x = timestamp_mean, 
               y = {{parameter}},
               ymin = {{parameter}} - {{err}},
               ymax = {{parameter}} + {{err}})) +
    geom_line(color = "gray") +
    geom_pointrange() +
    labs(x = NULL)
}
```

Select data (doesn't work yet)

```{r, eval=FALSE}
date_picker <- fluidPage(
  dateInput("start_date", "Start Date:", value = Sys.Date()),
)

includeHTML(widget = date_picker)
```

## Get and process data

### Get data from website. 

Use `start_date` parameter to limit download.

```{r}
baseURL <- "https://gems.whoi.edu/LECS_data/?timestamp="
queryURL <- paste0(baseURL, format(as.Date(params$start_date), "%Y%m%d%H"))
df_raw <- read_html(queryURL) |> 
  html_node("table") |> 
  html_table()
```

### Add row, type and line number

```{r}
df <- df_raw |> 
  mutate(row_num = row_number(),
         type = str_match(X1, "\\[\\d+\\]([DMS$!]):?")[,2],
         send = cumsum(type == "$"),
         line = as.integer(str_match(X1, "\\[(\\d+)\\][DMS$!]:?")[,2]),
         data = str_remove(X1, "\\[\\d+\\][DMS$!]:?")) |> 
  select(row_num, send, type, line, data)
```

### Separate data

#### Post times

```{r}
post_times <- df |> 
  filter(type == "$") |> 
  separate(data, 
           into = c('hour', 'min', 'sec', 
                    'day', 'month', 'year',
                    'lat', 'lon'),
           sep = ',') |>
  mutate(across(5:10, as.integer),
         across(11:12, as.numeric),
         timestamp = make_datetime(year, month, day, 
                                   hour, min, sec,
                                   tz = "America/New_York"),
         row_count = row_num - lag(row_num)) |> 
  select(timestamp, row_count)
```

#### Met data

```{r}
met <- df |> 
  filter(type == "M") |> 
  separate(data, 
           into = c('hour', 'min', 'sec', 
                    'day', 'month', 'year', 
                    'PAR', 'wind_speed', 'wind_dir'), 
           sep = ',') |> 
  mutate(wind_dir = str_sub(wind_dir, 1, 6),
         across(5:10, as.integer),
         across(11:13, as.numeric),
         wind_speed = ifelse(wind_speed < 99, wind_speed, NA),
         wind_dir = ifelse(wind_dir < 360, wind_dir, NA),
         timestamp = make_datetime(year, month, day, 
                                   hour, min, sec, 
                                   tz = "America/New_York")) |> 
  filter(timestamp > "2023-01-01",
         timestamp < "2024-10-01") |> 
  select(timestamp, send, PAR, wind_speed, wind_dir)

met_mean <- met |> 
  group_by(send) |> 
  summarise(across(everything(), 
                   list(mean = ~ mean(.x, na.rm = TRUE), 
                        sd = ~ sd(.x, na.rm = TRUE))))
```

#### ADV Status

```{r}
status <- df |> 
  filter(type == "S") |> 
  separate(data, 
           into = c('hour', 'min', 'sec', 'day', 'month', 'year',
                    'adv_min', 'adv_sec', 'adv_day', 
                    'adv_hour', 'adv_year', 'adv_month',
                    'bat', 'soundspeed', 'heading', 'pitch', 
                    'roll', 'temp', 
                    'pump_current', 'pump_voltage', 'pump_power'),
           sep = ',') |>
  mutate(pump_power = str_sub(pump_power, 1, 5),
         across(5:16, as.integer),
         across(17:25, ~ as.numeric(.x) * .1),
         timestamp = make_datetime(year, month, day, hour, min, sec,
                                   tz = "America/New_York"),
         adv_timestamp = make_datetime(adv_year + 2000, adv_month, adv_day, 
                                       adv_hour, adv_min, adv_sec, 
                                       tz = "America/New_York"))

status_qc <- status |> 
  filter(soundspeed > 1450, 
         adv_day < 32, adv_month > 0, adv_month < 13, 
         adv_min < 61, adv_hour < 24, adv_year < 100,
         timestamp > "2023-01-01",
         timestamp < "2024-10-01")

status_mean <- status_qc |> 
  select(send, timestamp, bat) |> 
  group_by(send) |> 
  summarise(across(c(timestamp, bat), 
                   list(mean = ~ mean(.x, na.rm = TRUE), 
                        sd = ~ sd(.x, na.rm = TRUE))))
```

#### ADV Data

```{r}
adv_data <- df |> 
  filter(type == "D") |> 
  separate(data, 
           into = c('count', 'pressure', 
                    'x_vel', 'y_vel', 'z_vel',
                    'x_amp', 'y_amp', 'z_amp',
                    'x_cor', 'y_cor', 'z_cor',
                    'ana_in', 'ana_in2', 'pH', 
                    'temp', 'oxy'),
           sep = ',') |>
  mutate(oxy = str_sub(oxy, 1, 10),
         across(6:20, as.numeric),
         count = as.integer(count),
         pressure = pressure / 65536 / 1000,
         temp = A + temp * B + temp ^ 2 * C + temp ^ 3 * D,
         missing = case_when(line == 1 | count > 255 | lag(count) > 255 ~ NA_integer_,
                             count > lag(count) ~ count - 1L - lag(count),
                             TRUE ~ 255L + count - lag(count)
                           ))

# quick and dirty time alignment
find_nearest_row <- function(row_number) {
  return(which.min(abs(status$row_num - row_number)))
}

adv_data$timestamp <- status$timestamp[sapply(adv_data$row_num, find_nearest_row)]

adv_data_qc <- adv_data |> 
  filter(count >= 0, count < 256, 
         ana_in2 == 1, 
         timestamp > "2023-01-01",
         timestamp < "2024-10-01")

adv_data_mean <- adv_data_qc |> 
  select(send, missing, timestamp, pressure, pH, temp, oxy) |> 
  group_by(send) |> 
  summarise(across(everything(), 
                   list(mean = ~ mean(.x, na.rm = TRUE), 
                        sd = ~ sd(.x, na.rm = TRUE))),
            missing_frac = sum(missing, na.rm = TRUE) / (sum(missing, na.rm = TRUE) + n()),
            N = n())
```

#### Last post was `r max(post_times$timestamp)`

### Met data

#### PAR

```{r}
met_mean |> 
  plot_mean(PAR_mean, PAR_sd)
```

#### Wind Speed

```{r}
met_mean |> 
  plot_mean(wind_speed_mean, wind_speed_sd) +
  labs(title = "Wind Speed",
       y = "Wind Speed (m/s)")
```

#### Wind direction

```{r}
ggplot(met_mean, aes(wind_dir_mean, wind_speed_mean)) +
  geom_point() +
  coord_polar() 
```

### Status

#### Battery

```{r}
status_mean |> 
  plot_mean(bat_mean, bat_sd) +
  geom_smooth() +
  labs(title = "Battery Voltage",
       y = "Volts")
```

### ADV Data

#### pressure

```{r}
adv_data_mean |> 
  plot_mean(pressure_mean, pressure_sd) +
  labs(title = "Pressure",
       y = "Pressure (dbar)")
```

#### pH

Data issues cause wild flyers

```{r}
adv_data_qc |> 
  ggplot(aes(timestamp, pH)) +
  geom_point()
```


```{r}
adv_data_mean |> 
  plot_mean(pH_mean, pH_sd) +
  labs(title = "pH")
```

#### Temperature

```{r}
adv_data_mean |> 
  plot_mean(temp_mean, temp_sd) +
  labs(title = "Temperature",
       y = "Temp (C)")
```

#### Oxygen

```{r}
adv_data_mean |> 
  plot_mean(oxy_mean, oxy_sd) +
  labs(title = "Oxygen")
```

## Missing data

Missing data by row. Determined by looking at gaps in cycle number.

```{r}
adv_data |> 
  ggplot(aes(timestamp, missing)) +
  geom_point() +
  labs(title = "Missing data by row",
       x = NULL,
       y = "Missing")
```

Fraction of data missing. Ratio of total missing rows (as above)
to expected rows (rows in send + sum of missing rows).

```{r}
adv_data_mean |> 
  ggplot(aes(timestamp_mean, missing_frac)) +
  geom_point() +
  labs(title = "Fraction missing by send",
       x = NULL,
       y = "Fraction missing")
```

## Post times

```{r}
knitr::kable(post_times)
```

Lines per post

```{r}
post_times |> 
  ggplot(aes(timestamp, row_count)) +
  geom_point() +
  labs(title = "Lines per post",
       x = NULL,
       y = "Lines")
```