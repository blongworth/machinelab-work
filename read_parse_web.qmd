---
title: "Parse LECS Web"
format: html
editor: source
---

Get and parse data sent to LECS website

# Get Data

```{r}
library(tidyverse)
library(rvest)
library(lubridate)
library(mlabtools)
library(tidyquant)

# time offset in seconds
ts_offset <- 671628945
```

Extract table

```{r}
df_raw <- read_html("https://gems.whoi.edu/LECSrawdata/") |> 
  html_node("table") |> 
  html_table()
```

Add row, type and line number

```{r}
df <- df_raw |> 
  mutate(row_num = row_number(),
         type = str_match(X1, "\\[\\d+\\]([DMS$]):?")[,2],
         line = as.integer(str_match(X1, "\\[(\\d+)\\][DMS$]:?")[,2]),
         data = str_remove(X1, "\\[\\d+\\][DMS$]:?")) |> 
  select(row_num, type, line, data)
```


```{r, eval=FALSE}
data <- df %>%
  mutate(row = row_number())
%>%
  pivot_longer(cols = -row, names_to = "col_type", values_to = "value")

data_s <- data %>%
  filter(col_type == "type" & value == "S") %>%
  select(col_type, value)

data_d <- data %>%
  filter(col_type == "type" & value == "D")

data_d <- data_d %>%
  group_by(grp = cumsum(line <= lag(line, default = 0))) %>%
  left_join(data_s, by = "line") %>%
  mutate(timestamp = if_else(is.na(value.y), 
                             lag(value.y, default = first(value.y)), 
                             value.y)) %>%
  select(-value.y) %>%
  ungroup()
```

## Met

```{r}
met <- df |> 
  filter(type == "M") |> 
  separate(data, 
           into = c('hour', 'min', 'sec', 'day', 'month', 'year', 'PAR', 'wind_speed', 'wind_dir'), 
           sep = ',') |> 
  mutate(across(3:8, as.integer),
         across(9:11, as.numeric)) |> 
  mutate(timestamp = make_datetime(year, month, day, hour, min, sec, tz = "America/New_York"))
```

### PAR

```{r}
ggplot(met, aes(timestamp, PAR)) + geom_line()
```

### Wind Speed

```{r}
ggplot(met, aes(timestamp, wind_speed)) + geom_line()
```

### Wind direction

```{r}
ggplot(met, aes(timestamp, wind_dir)) + geom_line()
```

## Status

```{r}
status <- df |> 
  filter(type == "S") |> 
  separate(data, 
           into = c('hour', 'min', 'sec', 'day', 'month', 'year',
                    'adv_min', 'adv_sec', 'adv_day', 
                    'adv_hour', 'adv_year', 'adv_month',
                    'bat', 'soundspeed', 'heading', 'pitch', 
                    'roll', 'temp', 
                    'pump_current', 'pump_voltage', 'pump_power'),
           sep = ',') |>
  mutate(across(3:14, as.integer),
         across(15:23, ~ as.numeric(.x) * .1),
         timestamp = make_datetime(year, month, day, hour, min, sec,
                                   tz = "America/New_York"),
         adv_timestamp = make_datetime(adv_year + 2000, adv_month, adv_day, adv_hour, adv_min, adv_sec, 
                                       tz = "America/New_York"),
         adv_timestamp_cor = adv_timestamp + ts_offset)

status_qc <- status |> 
  filter(soundspeed > 1450, 
         adv_day < 32, adv_month > 0, adv_month < 13, adv_min < 61, 
         adv_hour < 24, adv_year < 100)
```

### Battery

```{r}
status_qc |> 
  filter(year == 2023, month < 9) |> 
ggplot(aes(timestamp, bat)) +
  geom_line()
```

Recent battery

```{r}
status_qc |> 
  filter(year == 2023, month < 9, month > 6) |> 
ggplot(aes(timestamp, bat)) +
  geom_point(size = .5) +
  tidyquant::geom_ma(n = 20, linetype = 1)
```
## ADV Data

```{r}
adv_data <- df |> 
  filter(type == "D") |> 
  separate(data, 
           into = c('count', 'pressure', 
                    'x_vel', 'y_vel', 'z_vel',
                    'x_amp', 'y_amp', 'z_amp',
                    'x_cor', 'y_cor', 'z_cor',
                    'ana_in', 'ana_in2', 'pH', 
                    'temp', 'oxy'),
           sep = ',') |>
  mutate(across(4:18, as.numeric),
         count = as.integer(count))

adv_data_qc <- adv_data |> 
  filter(count >= 0, count < 256, 
         ana_in2 == 1) 
```

### pressure

```{r}
adv_data_qc |> 
  ggplot(aes(1:nrow(adv_data_qc), pressure)) + geom_line()
```

### pH

```{r}
adv_data_qc |> 
  ggplot(aes(1:nrow(adv_data_qc), pH)) +
  geom_line()
```

recent, filtered

```{r}
adv_data_qc |> 
  ggplot(aes(1:nrow(adv_data_qc), pH)) +
  geom_line() +
 xlim(17000, nrow(adv_data_qc)) +
 ylim(7000, 12000)
```

### temp

```{r}
adv_data_qc |> 
  ggplot(aes(1:nrow(adv_data_qc), temp)) + geom_line()
```

### Missing data

#### Plot missingness

TODO: running fraction missing plot

```{r}
adv_data <- adv_data |> 
  mutate(missing = case_when(line == 1 | count > 255 | lag(count) > 255 ~ NA_integer_,
                             count > lag(count) ~ count - 1L - lag(count),
                             TRUE ~ 255L + count - lag(count)
                           ))
```


```{r}
adv_data |> 
  ggplot(aes(row_num, missing)) +
  geom_point() #+
  #xlim(10000, nrow(adv_data)) +
  #ylim(0, 10)
```

```{r}
adv_data |> 
  ggplot(aes(row_num, missing)) +
  geom_point() +
  xlim(40000, max(adv_data$row_num)) #+
  #ylim(0, 10)
```

```{r}
adv_data |> 
  #drop_na(missing) |> 
  ggplot(aes(row_num, missing)) +
  tidyquant::geom_ma(n = 10, linetype = 1) 
```


## Post times

Add # lines per post

```{r}
post_times <- df |> 
  filter(type == "$") |> 
  separate(data, 
           into = c('hour', 'min', 'sec', 'day', 'month', 'year',
                    'lat', 'lon'),
           sep = ',') |>
  mutate(across(3:8, as.integer),
         across(9:10, as.numeric),
         timestamp = make_datetime(year, month, day, hour, min, sec,
                                   tz = "America/New_York"),
         row_count = row_num - lag(row_num))
```


```{r}
post_times |> 
  select(timestamp, row_num, row_count) |> 
tail(10)
```

```{r}
post_times |> 
  ggplot(aes(timestamp, row_count)) +
  geom_point()
```

```{r}
post_times |> 
  filter(timestamp > '2020-01-01') |> 
  ggplot(aes(timestamp, row_count)) +
  geom_point()
```
